{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸªª ID Card OCR â€” Arabic & French (PDF Input)\n",
    "\n",
    "Handles a **scanned PDF** where:\n",
    "- **Page 1** = Front of the ID card\n",
    "- **Page 2** = Back of the ID card\n",
    "\n",
    "Special feature: detects the **card serial number** (the first sequence of digits printed at the very top of the card) separately from the national ID number.\n",
    "\n",
    "Pipeline:\n",
    "1. Install dependencies\n",
    "2. Extract PDF pages â†’ images\n",
    "3. Pre-process each page\n",
    "4. Run bilingual OCR (Arabic + French)\n",
    "5. Detect **card serial number** by position (top 20% of card)\n",
    "6. Parse all other fields\n",
    "7. Visualise both sides\n",
    "8. Export unified JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Cell 1 â€” Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paddlepaddle paddleocr opencv-python-headless pillow \\\n",
    "             arabic-reshaper python-bidi matplotlib \\\n",
    "             pymupdf -q\n",
    "# pymupdf (import fitz) â€” fast, accurate PDF â†’ image conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Cell 2 â€” Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import json\n",
    "import fitz                          # PyMuPDF\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from paddleocr import PaddleOCR\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "print('âœ… All imports successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Cell 3 â€” Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ USER CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PDF_PATH             = \"id_card.pdf\"       # â† your scanned PDF\n",
    "FRONT_PAGE_INDEX     = 0                   # 0 = first page  (front of card)\n",
    "BACK_PAGE_INDEX      = 1                   # 1 = second page (back of card)\n",
    "PDF_DPI              = 300                 # higher = better quality, slower\n",
    "CONFIDENCE_THRESHOLD = 0.55\n",
    "USE_GPU              = False\n",
    "OUTPUT_JSON          = \"id_card_result.json\"\n",
    "\n",
    "# â”€â”€â”€ Card serial number detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# The card serial / document number is the FIRST numeric sequence visible\n",
    "# at the TOP of the card.  We detect it by:\n",
    "#   1. Looking only in the top region of the image (TOP_REGION_FRACTION)\n",
    "#   2. Matching a run of digits (SERIAL_PATTERN)\n",
    "TOP_REGION_FRACTION  = 0.20               # top 20 % of the card height\n",
    "SERIAL_PATTERN       = re.compile(r'\\b(\\d{4,})\\b')  # â‰¥4 consecutive digits\n",
    "\n",
    "# â”€â”€â”€ Bilingual field keywords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FIELD_KEYWORDS = {\n",
    "    \"last_name\": [\n",
    "        \"nom\", \"nom de famille\", \"surname\",\n",
    "        \"Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„ÙŠ\", \"Ø§Ø³Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©\", \"Ø§Ù„Ù†Ø³Ø¨\",\n",
    "    ],\n",
    "    \"first_name\": [\n",
    "        \"prÃ©nom\", \"prenom\", \"given name\",\n",
    "        \"Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø´Ø®ØµÙŠ\", \"Ø§Ù„Ø§Ø³Ù…\",\n",
    "    ],\n",
    "    \"dob\": [\n",
    "        \"date de naissance\", \"nÃ© le\", \"nÃ©e le\", \"naissance\",\n",
    "        \"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø²Ø¯ÙŠØ§Ø¯\", \"ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯\",\n",
    "    ],\n",
    "    \"pob\": [\n",
    "        \"lieu de naissance\", \"nÃ© Ã \", \"nÃ©e Ã \",\n",
    "        \"Ù…ÙƒØ§Ù† Ø§Ù„Ø§Ø²Ø¯ÙŠØ§Ø¯\", \"Ù…ÙƒØ§Ù† Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯\",\n",
    "    ],\n",
    "    \"expiry\": [\n",
    "        \"valable jusqu'au\", \"expire le\", \"date d'expiration\", \"valid until\",\n",
    "        \"ØµØ§Ù„Ø­Ø© Ø¥Ù„Ù‰\", \"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡\",\n",
    "    ],\n",
    "    \"id_number\": [\n",
    "        \"nÂ° carte\", \"numÃ©ro\", \"nÂ°\", \"cin\", \"id no\",\n",
    "        \"Ø±Ù‚Ù… Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©\", \"Ø±Ù‚Ù… Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆØ·Ù†ÙŠ\",\n",
    "    ],\n",
    "    \"address\": [\n",
    "        \"adresse\", \"domicile\", \"rÃ©sidence\",\n",
    "        \"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\", \"Ù…Ø­Ù„ Ø§Ù„Ø³ÙƒÙ†Ù‰\",\n",
    "    ],\n",
    "    \"nationality\": [\n",
    "        \"nationalitÃ©\", \"nationalite\",\n",
    "        \"Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\",\n",
    "    ],\n",
    "    \"sex\": [\n",
    "        \"sexe\", \"genre\",\n",
    "        \"Ø§Ù„Ø¬Ù†Ø³\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "DATE_PATTERN = re.compile(\n",
    "    r'\\b(\\d{1,2}[\\/-]\\d{1,2}[\\/-]\\d{2,4}|\\d{4}[\\/-]\\d{2}[\\/-]\\d{2})\\b'\n",
    ")\n",
    "# National ID number â€” adjust regex to your country\n",
    "# Morocco CIN: 1-2 letters + 5-6 digits | Algeria NNI: 18 digits\n",
    "ID_PATTERN = re.compile(r'\\b([A-Z]{1,2}\\d{5,6}|\\d{9,18})\\b')\n",
    "MRZ_PATTERN = re.compile(r'^[A-Z0-9<]{30,}$')\n",
    "\n",
    "print('âœ… Configuration loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Cell 4 â€” PDF â†’ Images (both pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_page_to_image(pdf_path: str, page_index: int, dpi: int = 300) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Render a single PDF page to a BGR numpy array using PyMuPDF.\n",
    "    DPI 300 is recommended for scanned documents.\n",
    "    \"\"\"\n",
    "    doc  = fitz.open(pdf_path)\n",
    "    if page_index >= len(doc):\n",
    "        raise IndexError(\n",
    "            f\"PDF has only {len(doc)} page(s); requested page index {page_index}.\"\n",
    "        )\n",
    "    page = doc[page_index]\n",
    "    zoom = dpi / 72                        # PyMuPDF default is 72 dpi\n",
    "    mat  = fitz.Matrix(zoom, zoom)\n",
    "    pix  = page.get_pixmap(matrix=mat, alpha=False)\n",
    "    img  = np.frombuffer(pix.samples, dtype=np.uint8)\n",
    "    img  = img.reshape(pix.height, pix.width, 3)   # RGB\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "def show_side_by_side(img1: np.ndarray, img2: np.ndarray,\n",
    "                      title1=\"Front\", title2=\"Back\"):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "    for ax, img, title in [(axes[0], img1, title1), (axes[1], img2, title2)]:\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(f'â³ Extracting pages from {PDF_PATH} at {PDF_DPI} DPI...')\n",
    "front_raw = pdf_page_to_image(PDF_PATH, FRONT_PAGE_INDEX, PDF_DPI)\n",
    "back_raw  = pdf_page_to_image(PDF_PATH, BACK_PAGE_INDEX,  PDF_DPI)\n",
    "\n",
    "print(f'   Front page shape : {front_raw.shape}')\n",
    "print(f'   Back  page shape : {back_raw.shape}')\n",
    "show_side_by_side(front_raw, back_raw, 'ğŸ“„ Front (raw)', 'ğŸ“„ Back (raw)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Cell 5 â€” Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_if_small(img: np.ndarray, min_side: int = 1000) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    scale = max(min_side / min(h, w), 1.0)\n",
    "    if scale > 1.0:\n",
    "        img = cv2.resize(img, (int(w * scale), int(h * scale)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "def denoise(img):\n",
    "    return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "\n",
    "def deskew(img: np.ndarray) -> np.ndarray:\n",
    "    gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180,\n",
    "                             threshold=80, minLineLength=80, maxLineGap=10)\n",
    "    if lines is None:\n",
    "        return img\n",
    "    angles = [np.degrees(np.arctan2(y2-y1, x2-x1))\n",
    "               for x1,y1,x2,y2 in lines[:,0]\n",
    "               if abs(np.degrees(np.arctan2(y2-y1, x2-x1))) < 45]\n",
    "    if not angles or abs(np.median(angles)) < 0.5:\n",
    "        return img\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), np.median(angles), 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h),\n",
    "                          flags=cv2.INTER_CUBIC,\n",
    "                          borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "def enhance_contrast(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return cv2.cvtColor(cv2.merge([clahe.apply(l), a, b]), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def sharpen(img):\n",
    "    k = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
    "    return cv2.filter2D(img, -1, k)\n",
    "\n",
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    img = resize_if_small(img)\n",
    "    img = denoise(img)\n",
    "    img = deskew(img)\n",
    "    img = enhance_contrast(img)\n",
    "    img = sharpen(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "print('â³ Pre-processing front page...')\n",
    "front = preprocess(front_raw)\n",
    "print('â³ Pre-processing back page...')\n",
    "back  = preprocess(back_raw)\n",
    "\n",
    "show_side_by_side(front, back, 'âœ… Front (processed)', 'âœ… Back (processed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¤ Cell 6 â€” Initialise OCR Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('â³ Loading Arabic OCR engine...')\n",
    "ocr_ar = PaddleOCR(use_angle_cls=True, lang='ar', use_gpu=USE_GPU, show_log=False)\n",
    "print('âœ… Arabic engine ready')\n",
    "\n",
    "print('â³ Loading French / Latin OCR engine...')\n",
    "ocr_fr = PaddleOCR(use_angle_cls=True, lang='fr', use_gpu=USE_GPU, show_log=False)\n",
    "print('âœ… French engine ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Cell 7 â€” OCR Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arabic(text: str) -> bool:\n",
    "    return bool(re.search(r'[\\u0600-\\u06FF]', text))\n",
    "\n",
    "def render_arabic(text: str) -> str:\n",
    "    if is_arabic(text):\n",
    "        return get_display(arabic_reshaper.reshape(text))\n",
    "    return text\n",
    "\n",
    "def extract_lines(ocr_engine, img: np.ndarray, language: str) -> list:\n",
    "    \"\"\"Run OCR and return list of dicts with text, confidence, bbox, position info.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    results = ocr_engine.ocr(img, cls=True)\n",
    "    lines = []\n",
    "    for page in results:\n",
    "        if not page:\n",
    "            continue\n",
    "        for item in page:\n",
    "            bbox, (text, conf) = item\n",
    "            text = text.strip()\n",
    "            if not text or conf < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "            pts = np.array(bbox)\n",
    "            cx  = float(pts[:, 0].mean())\n",
    "            cy  = float(pts[:, 1].mean())\n",
    "            # Normalised vertical position  0 = top, 1 = bottom\n",
    "            y_norm = cy / h\n",
    "            lines.append({\n",
    "                'text':       text,\n",
    "                'confidence': round(float(conf), 4),\n",
    "                'bbox':       bbox,\n",
    "                'language':   language,\n",
    "                'cx': cx, 'cy': cy,\n",
    "                'y_norm': round(y_norm, 4),    # â† used for serial detection\n",
    "            })\n",
    "    return lines\n",
    "\n",
    "\n",
    "def iou(b1, b2) -> float:\n",
    "    def to_rect(b):\n",
    "        pts = np.array(b); x1,y1 = pts.min(axis=0); x2,y2 = pts.max(axis=0)\n",
    "        return x1, y1, x2, y2\n",
    "    ax1,ay1,ax2,ay2 = to_rect(b1)\n",
    "    bx1,by1,bx2,by2 = to_rect(b2)\n",
    "    ix1,iy1 = max(ax1,bx1), max(ay1,by1)\n",
    "    ix2,iy2 = min(ax2,bx2), min(ay2,by2)\n",
    "    inter = max(0, ix2-ix1) * max(0, iy2-iy1)\n",
    "    union = (ax2-ax1)*(ay2-ay1) + (bx2-bx1)*(by2-by1) - inter\n",
    "    return inter/union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def deduplicate(ar_lines: list, fr_lines: list) -> list:\n",
    "    \"\"\"Merge Arabic + French results; resolve overlaps by script and confidence.\"\"\"\n",
    "    merged = list(ar_lines)\n",
    "    for fr in fr_lines:\n",
    "        overlap = False\n",
    "        for ar in ar_lines:\n",
    "            if iou(fr['bbox'], ar['bbox']) > 0.4:\n",
    "                overlap = True\n",
    "                # Both Latin â†’ keep higher confidence\n",
    "                if not is_arabic(ar['text']) and not is_arabic(fr['text']):\n",
    "                    if fr['confidence'] > ar['confidence']:\n",
    "                        merged = [fr if x is ar else x for x in merged]\n",
    "                break\n",
    "        if not overlap:\n",
    "            merged.append(fr)\n",
    "    # Reading order: top â†’ bottom, left â†’ right\n",
    "    merged.sort(key=lambda x: (round(x['cy'] / 30), x['cx']))\n",
    "    return merged\n",
    "\n",
    "\n",
    "def run_ocr_on_page(img: np.ndarray, label: str = '') -> list:\n",
    "    print(f'  Running Arabic OCR {label}...')\n",
    "    ar = extract_lines(ocr_ar, img, 'ar')\n",
    "    print(f'    â†’ {len(ar)} Arabic detections')\n",
    "    print(f'  Running French OCR {label}...')\n",
    "    fr = extract_lines(ocr_fr, img, 'fr')\n",
    "    print(f'    â†’ {len(fr)} French detections')\n",
    "    merged = deduplicate(ar, fr)\n",
    "    print(f'  Merged: {len(merged)} unique detections')\n",
    "    return merged\n",
    "\n",
    "print('âœ… Helper functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Cell 8 â€” Run OCR on Both Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nâ”€â”€ FRONT PAGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')\n",
    "front_lines = run_ocr_on_page(front, '(front)')\n",
    "\n",
    "print('\\nâ”€â”€ BACK PAGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')\n",
    "back_lines  = run_ocr_on_page(back,  '(back)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¢ Cell 9 â€” Card Serial Number Detection\n",
    "\n",
    "The **card serial / document number** is the first sequence of digits printed at the **very top** of the card.  \n",
    "Strategy: look only at detections whose vertical centre is within the top `TOP_REGION_FRACTION` of the image, then pick the **leftmost** numeric sequence found there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_card_serial(lines: list,\n",
    "                       top_fraction: float = TOP_REGION_FRACTION) -> dict | None:\n",
    "    \"\"\"\n",
    "    Identify the card serial number from OCR lines.\n",
    "\n",
    "    Algorithm:\n",
    "    1. Filter lines whose vertical centre is in the top `top_fraction` of the card.\n",
    "    2. Among those, find every token that is a run of â‰¥4 digits.\n",
    "    3. Sort candidates by their horizontal position (left â†’ right).\n",
    "    4. Return the FIRST (leftmost / topmost) candidate.\n",
    "\n",
    "    Returns a dict {serial, confidence, bbox, y_norm} or None.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    for item in lines:\n",
    "        if item['y_norm'] > top_fraction:        # outside top band â†’ skip\n",
    "            continue\n",
    "        for m in SERIAL_PATTERN.finditer(item['text']):\n",
    "            candidates.append({\n",
    "                'serial':     m.group(1),\n",
    "                'confidence': item['confidence'],\n",
    "                'bbox':       item['bbox'],\n",
    "                'y_norm':     item['y_norm'],\n",
    "                'cx':         item['cx'],\n",
    "                'cy':         item['cy'],\n",
    "                'full_text':  item['text'],\n",
    "            })\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    # Sort by (vertical position, then horizontal) â†’ topmost-left wins\n",
    "    candidates.sort(key=lambda c: (c['y_norm'], c['cx']))\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def visualise_top_region(img: np.ndarray, lines: list,\n",
    "                          serial_result: dict | None,\n",
    "                          top_fraction: float = TOP_REGION_FRACTION,\n",
    "                          title: str = ''):\n",
    "    \"\"\"Show the card with the top-region band and the detected serial highlighted.\"\"\"\n",
    "    vis  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).copy()\n",
    "    h, w = img.shape[:2]\n",
    "    band = int(h * top_fraction)\n",
    "\n",
    "    # Semi-transparent yellow band over the top region\n",
    "    overlay = vis.copy()\n",
    "    cv2.rectangle(overlay, (0, 0), (w, band), (255, 230, 50), -1)\n",
    "    vis = cv2.addWeighted(overlay, 0.25, vis, 0.75, 0)\n",
    "\n",
    "    # Mark all detections in the top band\n",
    "    for item in lines:\n",
    "        if item['y_norm'] <= top_fraction:\n",
    "            pts = np.array(item['bbox'], np.int32)\n",
    "            cv2.polylines(vis, [pts], True, (180, 180, 0), 2)\n",
    "\n",
    "    # Highlight the chosen serial box in green\n",
    "    if serial_result:\n",
    "        pts = np.array(serial_result['bbox'], np.int32)\n",
    "        cv2.polylines(vis, [pts], True, (0, 220, 80), 4)\n",
    "        x, y = pts[0]\n",
    "        cv2.putText(vis, f\"SERIAL: {serial_result['serial']}\",\n",
    "                    (x, max(y - 12, 0)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 200, 60), 2)\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.imshow(vis)\n",
    "    plt.title(title or 'Serial Number Detection', fontsize=13)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# â”€â”€ Run on front page (serial is usually on the front) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "serial_result = detect_card_serial(front_lines)\n",
    "\n",
    "print('\\nğŸ”¢ Card Serial Number Detection')\n",
    "print('â”€' * 40)\n",
    "if serial_result:\n",
    "    print(f\"  Serial number  : {serial_result['serial']}\")\n",
    "    print(f\"  Full text line : {serial_result['full_text']}\")\n",
    "    print(f\"  Confidence     : {serial_result['confidence']:.2f}\")\n",
    "    print(f\"  Vertical pos   : top {serial_result['y_norm']*100:.1f}% of card\")\n",
    "else:\n",
    "    print('  âš ï¸  No serial number found in the top region.')\n",
    "    print('  â†’ Try increasing TOP_REGION_FRACTION in Cell 3.')\n",
    "\n",
    "visualise_top_region(\n",
    "    front, front_lines, serial_result,\n",
    "    title=f\"ğŸ”¢ Serial Detection â€” top {TOP_REGION_FRACTION*100:.0f}% region (yellow)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Cell 10 â€” Parse All Fields (Both Sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_id_fields(lines: list) -> dict:\n",
    "    \"\"\"Extract structured fields from merged OCR lines.\"\"\"\n",
    "    fields = {k: None for k in FIELD_KEYWORDS}\n",
    "    fields['mrz']       = []\n",
    "    fields['all_dates'] = []\n",
    "    fields['all_text']  = [i['text'] for i in lines]\n",
    "\n",
    "    for i, item in enumerate(lines):\n",
    "        text  = item['text']\n",
    "        lower = text.lower()\n",
    "\n",
    "        # MRZ line\n",
    "        if MRZ_PATTERN.match(text):\n",
    "            fields['mrz'].append(text)\n",
    "            continue\n",
    "\n",
    "        # Dates\n",
    "        for m in DATE_PATTERN.finditer(text):\n",
    "            fields['all_dates'].append(m.group())\n",
    "\n",
    "        # National ID number\n",
    "        if not fields['id_number']:\n",
    "            m = ID_PATTERN.search(text)\n",
    "            if m:\n",
    "                fields['id_number'] = m.group(1)\n",
    "\n",
    "        # Keyword-based fields\n",
    "        for field, keywords in FIELD_KEYWORDS.items():\n",
    "            if fields[field]:\n",
    "                continue\n",
    "            if any(kw in lower or kw in text for kw in keywords):\n",
    "                if ':' in text:\n",
    "                    value = text.split(':', 1)[-1].strip()\n",
    "                elif 'ØŒ' in text:\n",
    "                    value = text.split('ØŒ', 1)[-1].strip()\n",
    "                elif i + 1 < len(lines):\n",
    "                    value = lines[i + 1]['text']\n",
    "                else:\n",
    "                    value = text\n",
    "                if value:\n",
    "                    fields[field] = value\n",
    "\n",
    "    # Assign dates heuristically\n",
    "    dates = fields['all_dates']\n",
    "    if dates:\n",
    "        if not fields['dob']:    fields['dob']    = dates[0]\n",
    "        if not fields['expiry'] and len(dates) >= 2:\n",
    "            fields['expiry'] = dates[-1]\n",
    "\n",
    "    return fields\n",
    "\n",
    "\n",
    "# Merge both sides for field parsing (front is primary)\n",
    "all_lines = front_lines + back_lines\n",
    "parsed    = parse_id_fields(all_lines)\n",
    "\n",
    "# Inject card serial detected in Cell 9\n",
    "parsed['card_serial'] = serial_result['serial'] if serial_result else None\n",
    "\n",
    "print('\\n' + 'â•'*52)\n",
    "print('         ğŸªª  PARSED ID CARD FIELDS')\n",
    "print('â•'*52)\n",
    "DISPLAY_ORDER = [\n",
    "    'card_serial', 'id_number', 'last_name', 'first_name',\n",
    "    'dob', 'pob', 'sex', 'nationality', 'address', 'expiry'\n",
    "]\n",
    "for field in DISPLAY_ORDER:\n",
    "    value = parsed.get(field)\n",
    "    display_val = render_arabic(str(value)) if value else 'â€”'\n",
    "    marker = 'ğŸ†”' if field == 'card_serial' else '  '\n",
    "    print(f'{marker} {field:<16}: {display_val}')\n",
    "\n",
    "if parsed['all_dates']:\n",
    "    print(f'\\n  All dates found : {parsed[\"all_dates\"]}')\n",
    "if parsed['mrz']:\n",
    "    print('\\n  MRZ Lines:')\n",
    "    for line in parsed['mrz']:\n",
    "        print(f'    {line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Cell 11 â€” Visualise OCR Boxes on Both Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOUR_MAP = {'ar': (255, 80, 80), 'fr': (50, 180, 255)}\n",
    "\n",
    "def annotate_page(img_bgr: np.ndarray, lines: list,\n",
    "                  serial: dict | None = None) -> np.ndarray:\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    draw    = ImageDraw.Draw(pil_img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\n",
    "            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', 20)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for item in lines:\n",
    "        pts    = [tuple(map(int, pt)) for pt in item['bbox']]\n",
    "        colour = COLOUR_MAP.get(item['language'], (0, 220, 0))\n",
    "        for j in range(4):\n",
    "            draw.line([pts[j], pts[(j+1)%4]], fill=colour, width=2)\n",
    "        label = render_arabic(item['text'])[:40]\n",
    "        x, y  = pts[0]\n",
    "        draw.text((x, max(y-22, 0)), label, fill=colour, font=font)\n",
    "\n",
    "    # Highlight serial box\n",
    "    if serial:\n",
    "        pts = [tuple(map(int, pt)) for pt in serial['bbox']]\n",
    "        for j in range(4):\n",
    "            draw.line([pts[j], pts[(j+1)%4]], fill=(0, 220, 80), width=4)\n",
    "        x, y = pts[0]\n",
    "        draw.text((x, max(y-26, 0)),\n",
    "                  f\"â–¶ SERIAL: {serial['serial']}\",\n",
    "                  fill=(0, 200, 60), font=font)\n",
    "\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "ann_front = annotate_page(front, front_lines, serial=serial_result)\n",
    "ann_back  = annotate_page(back,  back_lines)\n",
    "\n",
    "ar_patch = mpatches.Patch(color=(1.0, 0.31, 0.31), label='Arabic')\n",
    "fr_patch = mpatches.Patch(color=(0.20, 0.71, 1.0),  label='French')\n",
    "sn_patch = mpatches.Patch(color=(0.0,  0.86, 0.47), label='Card serial')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 11))\n",
    "for ax, img, title in [\n",
    "    (axes[0], ann_front, 'ğŸªª Front â€” OCR annotations'),\n",
    "    (axes[1], ann_back,  'ğŸªª Back â€” OCR annotations'),\n",
    "]:\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.legend(handles=[ar_patch, fr_patch, sn_patch],\n",
    "           loc='lower center', ncol=3, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Cell 12 â€” Confidence & Position Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "# Confidence histograms\n",
    "for ax, lang, colour, label in [\n",
    "    (axes[0], 'ar', '#FF5050', 'Arabic'),\n",
    "    (axes[1], 'fr', '#32B4FF', 'French'),\n",
    "]:\n",
    "    confs = [l['confidence'] for l in all_lines if l['language'] == lang]\n",
    "    ax.hist(confs or [0], bins=20, range=(0,1), color=colour,\n",
    "            edgecolor='white', alpha=0.85)\n",
    "    if confs:\n",
    "        ax.axvline(np.mean(confs), color='black', linestyle='--',\n",
    "                   label=f'Mean: {np.mean(confs):.2f}')\n",
    "    ax.set_title(f'{label} Confidence', fontsize=12)\n",
    "    ax.set_xlabel('Confidence'); ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "\n",
    "# Vertical distribution (where on the card detections appear)\n",
    "y_norms = [l['y_norm'] for l in front_lines]\n",
    "axes[2].hist(y_norms, bins=20, range=(0,1), color='#9B59B6',\n",
    "             edgecolor='white', alpha=0.85)\n",
    "axes[2].axvline(TOP_REGION_FRACTION, color='orange', linestyle='--',\n",
    "                linewidth=2, label=f'Top region ({TOP_REGION_FRACTION*100:.0f}%)')\n",
    "axes[2].set_title('Front: Vertical Position of Detections', fontsize=12)\n",
    "axes[2].set_xlabel('Normalised Y (0=top, 1=bottom)')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('OCR Analysis', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Cell 13 â€” Export to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_serialisable(lines: list) -> list:\n",
    "    out = []\n",
    "    for item in lines:\n",
    "        out.append({\n",
    "            **{k: v for k, v in item.items() if k not in ('bbox',)},\n",
    "            'bbox': [[float(x), float(y)] for x, y in item['bbox']],\n",
    "        })\n",
    "    return out\n",
    "\n",
    "\n",
    "output = {\n",
    "    'source_pdf': PDF_PATH,\n",
    "    'parsed_fields': {\n",
    "        k: v for k, v in parsed.items() if k != 'all_text'\n",
    "    },\n",
    "    'card_serial_detail': serial_result and {\n",
    "        'serial':     serial_result['serial'],\n",
    "        'confidence': serial_result['confidence'],\n",
    "        'y_norm':     serial_result['y_norm'],\n",
    "        'full_text':  serial_result['full_text'],\n",
    "        'bbox':       [[float(x), float(y)] for x, y in serial_result['bbox']],\n",
    "    },\n",
    "    'front_lines': make_serialisable(front_lines),\n",
    "    'back_lines':  make_serialisable(back_lines),\n",
    "}\n",
    "\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f'âœ… Results saved â†’ {OUTPUT_JSON}')\n",
    "print(f'   Front detections : {len(front_lines)}')\n",
    "print(f'   Back  detections : {len(back_lines)}')\n",
    "print(f'   Card serial      : {parsed.get(\"card_serial\")}')\n",
    "print(f'   ID number        : {parsed.get(\"id_number\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Cell 14 â€” Tuning the Serial Number Detector\n",
    "\n",
    "If the serial number was **not detected**, run this cell to explore what was found in the top region and adjust parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Diagnostic: what OCR found in the top portion of the front page â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PROBE_FRACTION = 0.30   # â† increase this to look lower on the card\n",
    "\n",
    "print(f'Detections in top {PROBE_FRACTION*100:.0f}% of front page:')\n",
    "print(f'{\"Y%\":>5}  {\"Conf\":>5}  {\"Lang\":>4}  Text')\n",
    "print('-' * 65)\n",
    "\n",
    "top_items = [l for l in front_lines if l['y_norm'] <= PROBE_FRACTION]\n",
    "top_items.sort(key=lambda x: (x['y_norm'], x['cx']))\n",
    "\n",
    "for item in top_items:\n",
    "    print(f\"{item['y_norm']*100:>4.1f}%  {item['confidence']:>5.2f}  \"\n",
    "          f\"{item['language']:>4}  {render_arabic(item['text'])}\")\n",
    "\n",
    "if not top_items:\n",
    "    print('  Nothing found. Try lowering CONFIDENCE_THRESHOLD or raising PROBE_FRACTION.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Reference\n",
    "\n",
    "| Parameter | Where | Effect |\n",
    "|---|---|---|\n",
    "| `TOP_REGION_FRACTION` | Cell 3 | Fraction of card height scanned for serial number |\n",
    "| `SERIAL_PATTERN` | Cell 3 | Regex matching the serial format (default: â‰¥4 digits) |\n",
    "| `CONFIDENCE_THRESHOLD` | Cell 3 | Drop OCR results below this score |\n",
    "| `PDF_DPI` | Cell 3 | Rendering resolution â€” 300 recommended, 400 for poor scans |\n",
    "| `FRONT_PAGE_INDEX` | Cell 3 | 0-based page index for the front of the card |\n",
    "| `BACK_PAGE_INDEX` | Cell 3 | 0-based page index for the back of the card |\n",
    "| `ID_PATTERN` | Cell 3 | Regex for the national ID number format |\n",
    "\n",
    "**Difference between `card_serial` and `id_number`:**\n",
    "- `card_serial` â€” the document/card serial printed at the **physical top** of the card, detected purely by **position** (topmost numeric string).\n",
    "- `id_number` â€” the **national identity number** found by matching keywords like `CIN`, `Ø±Ù‚Ù… Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©`, etc., or by pattern (letter + digits)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
