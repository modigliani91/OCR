{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸªª ID Card OCR â€” Arabic & French\n",
    "**Using PaddleOCR with multi-language support (Arabic + French)**\n",
    "\n",
    "This notebook walks through:\n",
    "1. Installing dependencies\n",
    "2. Pre-processing the ID card image\n",
    "3. Running OCR in Arabic and French separately\n",
    "4. Merging and parsing results into structured fields\n",
    "5. Visualising bounding boxes on the card\n",
    "6. Exporting results to JSON\n",
    "\n",
    "> âœ… Tested on Moroccan, Algerian, and Tunisian national ID cards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Cell 1 â€” Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once â€” restart kernel after installation\n",
    "!pip install paddlepaddle paddleocr opencv-python-headless pillow arabic-reshaper python-bidi matplotlib -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Cell 2 â€” Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Arabic text rendering helpers\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "print('âœ… All imports successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Cell 3 â€” Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ USER CONFIG â€” edit these â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "IMAGE_PATH = \"id_card.jpg\"          # â† Path to your ID card image\n",
    "CONFIDENCE_THRESHOLD = 0.55         # Drop detections below this score\n",
    "USE_GPU = False                     # Set True if CUDA GPU is available\n",
    "SAVE_ANNOTATED = True               # Save annotated output image\n",
    "OUTPUT_JSON = \"id_card_result.json\" # Output JSON filename\n",
    "\n",
    "# â”€â”€â”€ Field keywords in BOTH languages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FIELD_KEYWORDS = {\n",
    "    \"last_name\": [\n",
    "        # French\n",
    "        \"nom\", \"nom de famille\", \"surname\",\n",
    "        # Arabic\n",
    "        \"Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„ÙŠ\", \"Ø§Ø³Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©\", \"Ø§Ù„Ù†Ø³Ø¨\"\n",
    "    ],\n",
    "    \"first_name\": [\n",
    "        \"prÃ©nom\", \"prenom\", \"given name\",\n",
    "        \"Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø´Ø®ØµÙŠ\", \"Ø§Ù„Ø§Ø³Ù…\"\n",
    "    ],\n",
    "    \"dob\": [\n",
    "        \"date de naissance\", \"nÃ© le\", \"nÃ©e le\", \"naissance\",\n",
    "        \"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø²Ø¯ÙŠØ§Ø¯\", \"ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯\"\n",
    "    ],\n",
    "    \"pob\": [\n",
    "        \"lieu de naissance\", \"nÃ© Ã \", \"nÃ©e Ã \",\n",
    "        \"Ù…ÙƒØ§Ù† Ø§Ù„Ø§Ø²Ø¯ÙŠØ§Ø¯\", \"Ù…ÙƒØ§Ù† Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯\"\n",
    "    ],\n",
    "    \"expiry\": [\n",
    "        \"valable jusqu'au\", \"expire le\", \"date d'expiration\", \"valid until\",\n",
    "        \"ØµØ§Ù„Ø­Ø© Ø¥Ù„Ù‰\", \"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡\"\n",
    "    ],\n",
    "    \"id_number\": [\n",
    "        \"nÂ° carte\", \"numÃ©ro\", \"nÂ°\", \"cin\", \"id no\",\n",
    "        \"Ø±Ù‚Ù… Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©\", \"Ø±Ù‚Ù… Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆØ·Ù†ÙŠ\"\n",
    "    ],\n",
    "    \"address\": [\n",
    "        \"adresse\", \"domicile\", \"rÃ©sidence\",\n",
    "        \"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\", \"Ù…Ø­Ù„ Ø§Ù„Ø³ÙƒÙ†Ù‰\"\n",
    "    ],\n",
    "    \"nationality\": [\n",
    "        \"nationalitÃ©\", \"nationalite\",\n",
    "        \"Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\"\n",
    "    ],\n",
    "    \"sex\": [\n",
    "        \"sexe\", \"genre\",\n",
    "        \"Ø§Ù„Ø¬Ù†Ø³\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Date regex (handles DD/MM/YYYY, YYYY-MM-DD, DD-MM-YYYY, etc.)\n",
    "DATE_PATTERN = r\"\\b(\\d{1,2}[\\/-]\\d{1,2}[\\/-]\\d{2,4}|\\d{4}[\\/-]\\d{2}[\\/-]\\d{2})\\b\"\n",
    "\n",
    "# ID number pattern â€” adjust to your country format\n",
    "# Morocco CIN: 1-2 letters + 5-6 digits  |  Algeria NNI: 18 digits\n",
    "ID_PATTERN = r\"\\b([A-Z]{1,2}\\d{5,6}|\\d{9,18})\\b\"\n",
    "\n",
    "print(\"âœ… Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ–¼ï¸ Cell 4 â€” Load & Preview Raw Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str) -> np.ndarray:\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot load image: {path}\")\n",
    "    return img\n",
    "\n",
    "def show_image(img: np.ndarray, title: str = \"\", figsize=(14, 8)):\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "raw_img = load_image(IMAGE_PATH)\n",
    "show_image(raw_img, \"ğŸ–¼ï¸ Original ID Card\")\n",
    "print(f\"Image shape: {raw_img.shape}  (H Ã— W Ã— C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Cell 5 â€” Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_if_small(img: np.ndarray, min_side: int = 900) -> np.ndarray:\n",
    "    \"\"\"Upscale so the shortest side is at least `min_side` pixels.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    scale = max(min_side / min(h, w), 1.0)\n",
    "    if scale > 1.0:\n",
    "        img = cv2.resize(img, (int(w * scale), int(h * scale)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "\n",
    "def denoise(img: np.ndarray) -> np.ndarray:\n",
    "    return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "\n",
    "\n",
    "def sharpen(img: np.ndarray) -> np.ndarray:\n",
    "    kernel = np.array([[0, -1,  0],\n",
    "                       [-1,  5, -1],\n",
    "                       [0, -1,  0]])\n",
    "    return cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "\n",
    "def deskew(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Correct slight rotation using dominant edge angle.\"\"\"\n",
    "    gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180,\n",
    "                             threshold=80, minLineLength=80, maxLineGap=10)\n",
    "    if lines is None:\n",
    "        return img\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        if abs(angle) < 45:\n",
    "            angles.append(angle)\n",
    "    if not angles:\n",
    "        return img\n",
    "    median_angle = np.median(angles)\n",
    "    if abs(median_angle) < 0.5:\n",
    "        return img\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w / 2, h / 2), median_angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h),\n",
    "                          flags=cv2.INTER_CUBIC,\n",
    "                          borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "\n",
    "def enhance_contrast(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"CLAHE contrast enhancement on the L channel.\"\"\"\n",
    "    lab  = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l     = clahe.apply(l)\n",
    "    return cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "\n",
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    img = resize_if_small(img)\n",
    "    img = denoise(img)\n",
    "    img = deskew(img)\n",
    "    img = enhance_contrast(img)\n",
    "    img = sharpen(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "processed_img = preprocess(raw_img)\n",
    "show_image(processed_img, \"âœ… Pre-processed Image\")\n",
    "print(f\"Processed shape: {processed_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¤ Cell 6 â€” Initialise OCR Engines\n",
    "\n",
    "PaddleOCR does not support Arabic + French in a single model pass.  \n",
    "We run **two separate engines** and merge their results:\n",
    "- `arabic` model â€” detects Arabic script\n",
    "- `french` model (latin script via `fr`) â€” detects French / Latin text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â³ Loading Arabic OCR engine...\")\n",
    "ocr_ar = PaddleOCR(\n",
    "    use_angle_cls=True,\n",
    "    lang=\"ar\",          # Arabic model\n",
    "    use_gpu=USE_GPU,\n",
    "    show_log=False,\n",
    ")\n",
    "print(\"âœ… Arabic OCR engine ready\")\n",
    "\n",
    "print(\"â³ Loading French / Latin OCR engine...\")\n",
    "ocr_fr = PaddleOCR(\n",
    "    use_angle_cls=True,\n",
    "    lang=\"fr\",          # French (Latin) model\n",
    "    use_gpu=USE_GPU,\n",
    "    show_log=False,\n",
    ")\n",
    "print(\"âœ… French OCR engine ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Cell 7 â€” Run Both OCR Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lines(ocr_engine: PaddleOCR,\n",
    "                  img: np.ndarray,\n",
    "                  language: str,\n",
    "                  threshold: float = CONFIDENCE_THRESHOLD) -> list:\n",
    "    \"\"\"\n",
    "    Run OCR and return filtered list of dicts:\n",
    "      {text, confidence, bbox, language, bbox_center}\n",
    "    \"\"\"\n",
    "    results = ocr_engine.ocr(img, cls=True)\n",
    "    lines   = []\n",
    "    for page in results:\n",
    "        if not page:\n",
    "            continue\n",
    "        for item in page:\n",
    "            bbox, (text, conf) = item\n",
    "            text = text.strip()\n",
    "            if not text or conf < threshold:\n",
    "                continue\n",
    "            pts = np.array(bbox)\n",
    "            cx  = float(pts[:, 0].mean())\n",
    "            cy  = float(pts[:, 1].mean())\n",
    "            lines.append({\n",
    "                \"text\":       text,\n",
    "                \"confidence\": round(float(conf), 4),\n",
    "                \"bbox\":       bbox,\n",
    "                \"language\":   language,\n",
    "                \"bbox_center\": (cx, cy),\n",
    "            })\n",
    "    return lines\n",
    "\n",
    "\n",
    "def is_arabic(text: str) -> bool:\n",
    "    \"\"\"Return True if the string contains Arabic characters.\"\"\"\n",
    "    return bool(re.search(r'[\\u0600-\\u06FF\\u0750-\\u077F]', text))\n",
    "\n",
    "\n",
    "def deduplicate(ar_lines: list, fr_lines: list,\n",
    "                iou_threshold: float = 0.4) -> list:\n",
    "    \"\"\"\n",
    "    Merge Arabic and French OCR outputs.\n",
    "    If two detections overlap substantially (same bounding box region),\n",
    "    prefer the one whose language matches the script of the recognised text.\n",
    "    \"\"\"\n",
    "    def bbox_to_rect(bbox):\n",
    "        pts = np.array(bbox)\n",
    "        x1, y1 = pts.min(axis=0)\n",
    "        x2, y2 = pts.max(axis=0)\n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "    def iou(b1, b2):\n",
    "        ax1, ay1, ax2, ay2 = bbox_to_rect(b1)\n",
    "        bx1, by1, bx2, by2 = bbox_to_rect(b2)\n",
    "        ix1 = max(ax1, bx1); iy1 = max(ay1, by1)\n",
    "        ix2 = min(ax2, bx2); iy2 = min(ay2, by2)\n",
    "        inter = max(0, ix2 - ix1) * max(0, iy2 - iy1)\n",
    "        union = (ax2-ax1)*(ay2-ay1) + (bx2-bx1)*(by2-by1) - inter\n",
    "        return inter / union if union > 0 else 0.0\n",
    "\n",
    "    merged = list(ar_lines)          # start with Arabic results\n",
    "    for fr_item in fr_lines:\n",
    "        overlap = False\n",
    "        for ar_item in ar_lines:\n",
    "            if iou(fr_item[\"bbox\"], ar_item[\"bbox\"]) > iou_threshold:\n",
    "                overlap = True\n",
    "                # Keep the result whose model matches the detected script\n",
    "                if is_arabic(ar_item[\"text\"]) and not is_arabic(fr_item[\"text\"]):\n",
    "                    pass   # keep Arabic result already in merged\n",
    "                elif not is_arabic(ar_item[\"text\"]) and not is_arabic(fr_item[\"text\"]):\n",
    "                    # Both Latin â€” keep higher confidence\n",
    "                    if fr_item[\"confidence\"] > ar_item[\"confidence\"]:\n",
    "                        merged = [fr_item if x is ar_item else x for x in merged]\n",
    "                break\n",
    "        if not overlap:\n",
    "            merged.append(fr_item)\n",
    "\n",
    "    # Sort top-to-bottom, then left-to-right (reading order)\n",
    "    merged.sort(key=lambda x: (round(x[\"bbox_center\"][1] / 30), x[\"bbox_center\"][0]))\n",
    "    return merged\n",
    "\n",
    "\n",
    "print(\"â³ Running Arabic OCR...\")\n",
    "ar_lines = extract_lines(ocr_ar, processed_img, language=\"ar\")\n",
    "print(f\"   Found {len(ar_lines)} Arabic detections\")\n",
    "\n",
    "print(\"â³ Running French OCR...\")\n",
    "fr_lines = extract_lines(ocr_fr, processed_img, language=\"fr\")\n",
    "print(f\"   Found {len(fr_lines)} French detections\")\n",
    "\n",
    "print(\"â³ Merging & deduplicating...\")\n",
    "all_lines = deduplicate(ar_lines, fr_lines)\n",
    "print(f\"âœ… Total unique detections after merge: {len(all_lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Cell 8 â€” Display Raw OCR Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_arabic(text: str) -> str:\n",
    "    \"\"\"Reshape + apply BiDi so Arabic renders correctly in matplotlib.\"\"\"\n",
    "    if is_arabic(text):\n",
    "        return get_display(arabic_reshaper.reshape(text))\n",
    "    return text\n",
    "\n",
    "\n",
    "print(f\"{'#':>3}  {'Lang':>4}  {'Conf':>6}  Text\")\n",
    "print(\"-\" * 70)\n",
    "for i, item in enumerate(all_lines, 1):\n",
    "    display_text = render_arabic(item['text'])\n",
    "    print(f\"{i:>3}  {item['language']:>4}  {item['confidence']:>6.2f}  {display_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Cell 9 â€” Field Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_id_fields(lines: list) -> dict:\n",
    "    \"\"\"\n",
    "    Extract structured fields from the merged OCR lines using:\n",
    "    - Keyword matching (bilingual)\n",
    "    - Regex for dates, ID numbers, MRZ\n",
    "    \"\"\"\n",
    "    fields = {k: None for k in FIELD_KEYWORDS}\n",
    "    fields[\"mrz\"]       = []\n",
    "    fields[\"all_dates\"] = []\n",
    "    fields[\"all_text\"]  = [item[\"text\"] for item in lines]\n",
    "\n",
    "    MRZ_RE = re.compile(r'^[A-Z0-9<]{30,}$')\n",
    "\n",
    "    for i, item in enumerate(lines):\n",
    "        text  = item[\"text\"]\n",
    "        lower = text.lower()\n",
    "\n",
    "        # â”€â”€ MRZ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if MRZ_RE.match(text):\n",
    "            fields[\"mrz\"].append(text)\n",
    "            continue\n",
    "\n",
    "        # â”€â”€ Dates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        for m in re.finditer(DATE_PATTERN, text):\n",
    "            fields[\"all_dates\"].append(m.group())\n",
    "\n",
    "        # â”€â”€ ID number â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if not fields[\"id_number\"]:\n",
    "            m = re.search(ID_PATTERN, text)\n",
    "            if m:\n",
    "                fields[\"id_number\"] = m.group(1)\n",
    "\n",
    "        # â”€â”€ Keyword fields â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        for field, keywords in FIELD_KEYWORDS.items():\n",
    "            if fields[field]:             # already found\n",
    "                continue\n",
    "            if any(kw in lower or kw in text for kw in keywords):\n",
    "                # Value is either after ':' on same line or on next line\n",
    "                if \":\" in text:\n",
    "                    value = text.split(\":\", 1)[-1].strip()\n",
    "                elif \"ØŒ\" in text:         # Arabic comma\n",
    "                    value = text.split(\"ØŒ\", 1)[-1].strip()\n",
    "                elif i + 1 < len(lines):\n",
    "                    value = lines[i + 1][\"text\"]\n",
    "                else:\n",
    "                    value = text\n",
    "                if value:\n",
    "                    fields[field] = value\n",
    "\n",
    "    # Assign dates heuristically if not found via keywords\n",
    "    dates = fields[\"all_dates\"]\n",
    "    if dates:\n",
    "        if not fields[\"dob\"]:\n",
    "            fields[\"dob\"]    = dates[0]\n",
    "        if not fields[\"expiry\"] and len(dates) >= 2:\n",
    "            fields[\"expiry\"] = dates[-1]\n",
    "\n",
    "    return fields\n",
    "\n",
    "\n",
    "parsed = parse_id_fields(all_lines)\n",
    "\n",
    "print(\"\\n\" + \"â•\" * 50)\n",
    "print(\"          ğŸªª  PARSED ID CARD FIELDS\")\n",
    "print(\"â•\" * 50)\n",
    "for field, value in parsed.items():\n",
    "    if field in (\"all_text\", \"mrz\", \"all_dates\"):\n",
    "        continue\n",
    "    display_val = render_arabic(str(value)) if value else \"â€”\"\n",
    "    print(f\"  {field:<15}: {display_val}\")\n",
    "\n",
    "if parsed[\"all_dates\"]:\n",
    "    print(f\"\\n  All dates found : {parsed['all_dates']}\")\n",
    "\n",
    "if parsed[\"mrz\"]:\n",
    "    print(\"\\n  MRZ Lines:\")\n",
    "    for line in parsed[\"mrz\"]:\n",
    "        print(f\"    {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Cell 10 â€” Visualise OCR Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOUR_MAP = {\"ar\": (255, 80,  80),   # red for Arabic\n",
    "              \"fr\": (50,  180, 255)}  # blue for French\n",
    "\n",
    "def annotate_image_pil(img_bgr: np.ndarray, lines: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw coloured bounding boxes + text labels using PIL so Arabic\n",
    "    characters render correctly.\n",
    "    \"\"\"\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    draw    = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    # Try to load a font that supports Arabic; fall back to default\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 18)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for item in lines:\n",
    "        pts    = [tuple(map(int, pt)) for pt in item[\"bbox\"]]\n",
    "        colour = COLOUR_MAP.get(item[\"language\"], (0, 220, 0))\n",
    "\n",
    "        # Draw polygon\n",
    "        draw.polygon(pts, outline=colour)\n",
    "        for j in range(4):\n",
    "            draw.line([pts[j], pts[(j+1) % 4]], fill=colour, width=2)\n",
    "\n",
    "        # Label text (reshaped if Arabic)\n",
    "        label = render_arabic(item[\"text\"])\n",
    "        x, y  = pts[0]\n",
    "        draw.text((x, max(y - 20, 0)), label[:40], fill=colour, font=font)\n",
    "\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "annotated = annotate_image_pil(processed_img, all_lines)\n",
    "\n",
    "# Legend\n",
    "ar_patch = mpatches.Patch(color=(1, 0.31, 0.31), label='Arabic detections')\n",
    "fr_patch = mpatches.Patch(color=(0.20, 0.71, 1.0), label='French detections')\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "plt.legend(handles=[ar_patch, fr_patch], loc='lower right', fontsize=12)\n",
    "plt.title(\"OCR Detections â€” Arabic (red) & French (blue)\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if SAVE_ANNOTATED:\n",
    "    out_path = Path(IMAGE_PATH).stem + \"_annotated.jpg\"\n",
    "    cv2.imwrite(out_path, annotated)\n",
    "    print(f\"ğŸ’¾ Annotated image saved â†’ {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Cell 11 â€” Confidence Distribution Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_conf = [l[\"confidence\"] for l in all_lines if l[\"language\"] == \"ar\"]\n",
    "fr_conf = [l[\"confidence\"] for l in all_lines if l[\"language\"] == \"fr\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "for ax, confs, label, colour in [\n",
    "    (axes[0], ar_conf, \"Arabic\",  \"#FF5050\"),\n",
    "    (axes[1], fr_conf, \"French\",  \"#32B4FF\"),\n",
    "]:\n",
    "    ax.hist(confs, bins=20, range=(0, 1), color=colour, edgecolor=\"white\", alpha=0.85)\n",
    "    ax.axvline(np.mean(confs) if confs else 0, color=\"black\", linestyle=\"--\",\n",
    "               label=f\"Mean: {np.mean(confs):.2f}\" if confs else \"No data\")\n",
    "    ax.set_title(f\"{label} Confidence Distribution\", fontsize=13)\n",
    "    ax.set_xlabel(\"Confidence\"); ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Cell 12 â€” Export Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialise(obj):\n",
    "    \"\"\"Make bbox (list of lists of floats) JSON-safe.\"\"\"\n",
    "    if isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    raise TypeError(f\"Not serialisable: {type(obj)}\")\n",
    "\n",
    "\n",
    "output = {\n",
    "    \"source_image\":  IMAGE_PATH,\n",
    "    \"parsed_fields\": {\n",
    "        k: v for k, v in parsed.items()\n",
    "        if k not in (\"all_text\",)\n",
    "    },\n",
    "    \"raw_lines\": [\n",
    "        {\n",
    "            **line,\n",
    "            \"bbox\": [[float(x), float(y)] for x, y in line[\"bbox\"]],\n",
    "            \"bbox_center\": [float(line[\"bbox_center\"][0]),\n",
    "                            float(line[\"bbox_center\"][1])],\n",
    "        }\n",
    "        for line in all_lines\n",
    "    ],\n",
    "}\n",
    "\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2, default=serialise)\n",
    "\n",
    "print(f\"âœ… Results saved â†’ {OUTPUT_JSON}\")\n",
    "print(f\"   Total lines exported : {len(all_lines)}\")\n",
    "print(f\"   Fields extracted     : {sum(1 for v in parsed.values() if v and v != [] and isinstance(v, str))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Cell 13 â€” Batch Processing (Multiple Cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(image_paths: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Process multiple ID card images and return a list of results.\n",
    "    Each result contains the source path and parsed fields.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for path in image_paths:\n",
    "        print(f\"\\n--- Processing: {path} ---\")\n",
    "        try:\n",
    "            img   = load_image(path)\n",
    "            proc  = preprocess(img)\n",
    "            ar_l  = extract_lines(ocr_ar, proc, \"ar\")\n",
    "            fr_l  = extract_lines(ocr_fr, proc, \"fr\")\n",
    "            lines = deduplicate(ar_l, fr_l)\n",
    "            flds  = parse_id_fields(lines)\n",
    "            results.append({\"image\": path, \"fields\": flds, \"raw_lines\": lines})\n",
    "            print(f\"  âœ… id_number={flds.get('id_number')}  \"\n",
    "                  f\"dob={flds.get('dob')}  expiry={flds.get('expiry')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Error: {e}\")\n",
    "            results.append({\"image\": path, \"error\": str(e)})\n",
    "    return results\n",
    "\n",
    "\n",
    "# â”€â”€ Example usage (uncomment and edit paths) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# batch_images = [\"card1.jpg\", \"card2.jpg\", \"card3.png\"]\n",
    "# batch_results = process_batch(batch_images)\n",
    "#\n",
    "# with open(\"batch_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(batch_results, f, ensure_ascii=False, indent=2)\n",
    "# print(\"Batch complete â€” results saved to batch_results.json\")\n",
    "\n",
    "print(\"Batch processing function defined. Uncomment the example lines above to run it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Notes & Tips\n",
    "\n",
    "| Topic | Guidance |\n",
    "|---|---|\n",
    "| **Languages** | `lang=\"ar\"` for Arabic, `lang=\"fr\"` for French/Latin. PaddleOCR 2.x does not support mixed-script in a single engine. |\n",
    "| **GPU** | Set `USE_GPU = True` and install `paddlepaddle-gpu` for 5â€“10Ã— speedup. |\n",
    "| **ID number regex** | `ID_PATTERN` in Cell 3 â€” update to match your country's format (Morocco CIN, Algeria NNI, Tunisia CIN, etc.). |\n",
    "| **Field keywords** | Extend `FIELD_KEYWORDS` in Cell 3 if your card uses different label wording. |\n",
    "| **MRZ parsing** | For full ICAO 9303 MRZ decoding, add the `mrz` library: `pip install mrz`. |\n",
    "| **Poor results?** | Try increasing image resolution before scanning, or crop the card tightly before passing to `preprocess()`. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
